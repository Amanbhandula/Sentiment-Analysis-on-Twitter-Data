{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"processedCorpus.csv\", names=[\"Tweet\", \"Sentiment\"])\n",
    "\n",
    "X = data_set.iloc[:, :-1]\n",
    "y = data_set.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(X[\"Tweet\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMClassifier=SVC()\n",
    "\n",
    "SVMClassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred = SVMClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6852689793866265"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[659, 324],\n",
       "       [302, 704]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict The sentiment\n",
      "Enter your data to get the sentiment: 'so unhappy hate'\n",
      "[1]\n",
      "['so unhappy hate']\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict The sentiment\")\n",
    "data = input(\"Enter your data to get the sentiment: \")\n",
    "data = [data]\n",
    "\n",
    "array = cv.transform(data).toarray()\n",
    "\n",
    "r = SVMClassifier.predict(array)\n",
    "print(r)\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key='6b9ebwaNU4DDa9G9xF1FhrZQt',\n",
    "                 consumer_secret='2prgddykMj2b7b9zTeN78BBhdrgdaNxjtSyyoo8iNRzKAZhzMX',\n",
    "                 access_token_key='817521154847969280-bc6J796tc0cRjlhigiRZIoQVIzeW2Hf',\n",
    "                 access_token_secret='WAZy2gZ9Ok8NdP3W8TOMNliSUUGrLjesudvqA3nEEh9wH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for: '@realDonaldTrump'\n",
      "num tweets: 100 term: @realDonaldTrump\n"
     ]
    }
   ],
   "source": [
    "def createTestData(search_string):\n",
    "    try:\n",
    "        tweets_fetched=api.GetSearch(search_string, count=500)\n",
    "        \n",
    "        print \"num tweets: \"+str(len(tweets_fetched))+\" term: \"+search_string\n",
    "        \n",
    "        return [status.text for status in tweets_fetched]\n",
    "    except:\n",
    "        print \"Error\"\n",
    "        return None\n",
    "    \n",
    "search_string=input(\"Search for: \")\n",
    "testData=createTestData(search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords=set(stopwords.words('english')+list(punctuation)+['rt', \"'s\", 'i'])\n",
    "        \n",
    "    def processTweets(self, list_of_tweets):\n",
    "        \n",
    "        processedTweets=[]\n",
    "        \n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweet=self._processTweet(tweet)\n",
    "            if len(processedTweet) > 0:\n",
    "                processedTweets.append(processedTweet)  \n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self, tweet):\n",
    "        \n",
    "        tweet=tweet.lower()\n",
    "        \n",
    "        tweet=re.sub('https?://[^\\s]+','',tweet)\n",
    "        \n",
    "        tweet=re.sub(r'@[^\\s]+','',tweet)\n",
    "        \n",
    "        tweet=re.sub(r'#([^\\s]+)',r'\\1',tweet)\n",
    "        \n",
    "        tweet=re.sub(\"[^a-z]\", \" \",tweet)\n",
    "        \n",
    "        tweet=word_tokenize(tweet)\n",
    "        \n",
    "        stemmer=PorterStemmer()\n",
    "        tweet=[stemmer.stem(word) for word in tweet]\n",
    "        stripper = lambda word: word.strip()\n",
    "        tweet = list(map(stripper, tweet))\n",
    "        tweet = filter(None, tweet)\n",
    "       \n",
    "        tweet=[word for word in tweet if word not in self._stopwords]\n",
    "        tweet= \" \".join(tweet)\n",
    "        return tweet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetProcessor=PreProcessTweets()\n",
    "ppTestData=tweetProcessor.processTweets(testData)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'play polit game believ get make rule consti', u'founder creat govern peopl king let w', u'stun approv among gop voter highest sinc wwii except gwb post trump day coup', u'play polit game believ get make rule constitut', u'lol littl desper benedictdonni project hi treason upon muelleriscom end nigh traitor', u'last person speak transpar tax return', u'con man egomaniac treason innoc man pardon themselv said', u'take long inspector gener report crook hillari slipperi jame comey numer delay', u'take long inspector gener report crook hillari slipperi jame comey numer delay', u'take long inspector gener report crook hillari slipperi jame comey numer delay']\n"
     ]
    }
   ],
   "source": [
    "print ppTestData[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Positive Sentiment: 95\n"
     ]
    }
   ],
   "source": [
    "ResultLabels=[]\n",
    "for tweet in ppTestData:\n",
    "    Features=cv.transform([tweet]).toarray()\n",
    "    ResultLabels.append(SVMClassifier.predict(Features)[0])\n",
    "    \n",
    "\n",
    "if ResultLabels.count(1)>ResultLabels.count(0):\n",
    "    print \"Result Positive Sentiment: \" + str(100*ResultLabels.count(1)/len(ResultLabels))\n",
    "else:\n",
    "     print \"Result Negative Sentiment: \" + str(100*ResultLabels.count(0)/len(ResultLabels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
